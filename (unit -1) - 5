import numpy as np

# 1. Environment Setup
grid_size = (5, 5)
pickup_points = [(0, 4), (4, 0)]
passenger_location = (2, 2) # Taxi starts here to find a pickup point
obstacles = [(1, 1), (1, 3), (3, 1), (3, 3)]
actions = ['up', 'down', 'left', 'right']

# Rewards
step_penalty = -1
pickup_reward = 20
obstacle_penalty = -10

# 2. Value Iteration Algorithm
gamma = 0.9 # Discount factor
theta = 1e-6 # Convergence threshold
value_function = np.zeros(grid_size)

while True:
    delta = 0
    for r in range(grid_size[0]):
        for c in range(grid_size[1]):
            state = (r, c)
            v = value_function[state]
            
            # If terminal state, value is 0
            if state in pickup_points:
                continue

            # Find the max value over all possible actions
            action_values = []
            for action_idx in range(len(actions)):
                next_state = list(state)
                if action_idx == 0 and r > 0: next_state[0] -= 1
                elif action_idx == 1 and r < grid_size[0] - 1: next_state[0] += 1
                elif action_idx == 2 and c > 0: next_state[1] -= 1
                elif action_idx == 3 and c < grid_size[1] - 1: next_state[1] += 1
                next_state = tuple(next_state)
                
                reward = step_penalty
                # If action leads into an obstacle, taxi stays put but gets penalty
                if next_state in obstacles:
                    reward = obstacle_penalty
                    next_state = state 
                elif next_state in pickup_points:
                    reward = pickup_reward

                action_values.append(reward + gamma * value_function[next_state])
            
            value_function[state] = max(action_values)
            delta = max(delta, abs(v - value_function[state]))
            
    if delta < theta:
        break

print("Value Iteration Converged. Optimal Value Function:")
print(np.round(value_function, 1))

# 3. Extract Optimal Policy
policy = np.zeros(grid_size, dtype=int)
for r in range(grid_size[0]):
    for c in range(grid_size[1]):
        state = (r, c)
        if state in pickup_points: continue
            
        action_values = []
        for action_idx in range(len(actions)):
            next_state = list(state)
            if action_idx == 0 and r > 0: next_state[0] -= 1
            elif action_idx == 1 and r < grid_size[0] - 1: next_state[0] += 1
            elif action_idx == 2 and c > 0: next_state[1] -= 1
            elif action_idx == 3 and c < grid_size[1] - 1: next_state[1] += 1
            next_state = tuple(next_state)

            reward = step_penalty
            if next_state in obstacles:
                reward = obstacle_penalty
                next_state = state
            elif next_state in pickup_points:
                reward = pickup_reward
            
            action_values.append(reward + gamma * value_function[next_state])
        
        policy[state] = np.argmax(action_values)

# 4. Display Optimal Policy
policy_symbols = ['↑', '↓', '←', '→']
optimal_policy_grid = np.full(grid_size, ' ', dtype=str)

for r in range(grid_size[0]):
    for c in range(grid_size[1]):
        if (r, c) in obstacles: optimal_policy_grid[r, c] = 'X'
        elif (r, c) in pickup_points: optimal_policy_grid[r, c] = 'P'
        elif (r,c) == passenger_location: optimal_policy_grid[r,c] = 'T'
        else: optimal_policy_grid[r, c] = policy_symbols[policy[r, c]]

print("\nOptimal Taxi Dispatch Policy (T: Taxi Start, P: Pickup, X: Obstacle):")
print(optimal_policy_grid)
